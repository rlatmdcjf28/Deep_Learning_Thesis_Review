# ğŸ“„ DETR - One Stage Detector(Anchor Free)
<br>
<br>

## ğŸ” Research Background & Idea
### object detectionì˜ goalì€ each interest objectì— ëŒ€í•´ a set of bounding boxesì™€ category labelsì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ë‹¤.
### Modern detectorsëŠ” large set of proposals, anchors, window centersë¥¼ í†µí•´ prediction ì‘ì—…ì„ ê°„ì ‘ì ìœ¼ë¡œ í•´ê²°í•œë‹¤.
### ìœ„ detectorë“¤ì˜ ì„±ëŠ¥ì€ duplicate predictionì„ ì œê±°í•˜ê¸° ìœ„í•œ postprocessing(NMS), anchor setì˜ ì„¤ê³„ ë° target boxë¥¼ anchorì— í• ë‹¹í•˜ëŠ” heuristicì— í° ì˜í–¥ì„ ë°›ëŠ”ë‹¤.
### ì´ë¥¼ ë‹¨ìˆœí™” í•˜ê¸° ìœ„í•´ ì €ìë“¤ì€ surrogate tasksì„ ìš°íšŒí•˜ëŠ” direct set prediction ì ‘ê·¼ë²•ì„ ì œì•ˆ.
### ë˜í•œ, DETRì€ Anchor boxesë‚˜ NMSì™€ ê°™ì€ hand designëœ componentsë¥¼ ì œê±°í•˜ì—¬ detection piplineì„ ë‹¨ìˆœí™”í•œë‹¤.
### DETRì€ ì´ì „ì˜ Detectorsì—ì„œ ì‚¬ìš©ë˜ë˜ Anchor boxesë¥¼ ì„¤ê³„í•˜ì§€ ì•Šê³ , a set of predictionìœ¼ë¡œ detectionì„ ì§„í–‰í•œë‹¤.
### NLPì—ì„œ popular architectureê°€ ëœ Transformer ê¸°ë°˜ì˜ Encoder-Decoder Architectureê°€ set prediction taskì— ì í•©í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ Object Detectionì—ë„ ì ìš©.
### ë˜í•œ predictëœ objectì™€ ground truth(GT) object ê°„ì˜ bipartite matchingì„ ìˆ˜í–‰í•˜ëŠ” a set loss functionì„ ì‚¬ìš©í•œë‹¤.

<br>

![simple model architecture - ref : official paper](https://github.com/user-attachments/assets/41ce9ed5-8070-4049-8272-e5bfd671e699) [ê°„ë‹¨í•œ ëª¨ë¸ êµ¬ì¡° ê·¸ë¦¼]

<br>
<br>


## ğŸ” Model Code (ref : official code)
### â“µ â“¶ â“· â“¸ â“¹ â“º â“» â“¼ â“½ â“ª
### 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ 4ï¸âƒ£ 5ï¸âƒ£ 6ï¸âƒ£ 7ï¸âƒ£ 8ï¸âƒ£ 9ï¸âƒ£ 0ï¸âƒ£

### 1ï¸âƒ£ DETR.forward (samples : NestedTensor)
```python
"""
forwardë¡œ NestedTensorê°€ ì…ë ¥ë˜ì–´ì•¼ í•¨. NestedTensorì˜ êµ¬ì„±ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŒ
â“µ samples.tensor -> batch image = (bs, 3, H, W)
â“¶ samples.mask   -> binary mask = (bs, H, W)

ë‹¤ìŒ elementë¥¼ return.
â“µ pred_logits -> classification logits(include no-object) for all queries = (bs, n_q, n_cls+1)
â“¶ pred_boxes  -> normalizedëœ box coordinates for all queries = (cx, cy, h, w)
â“· aux_outputs -> optional. only return when auxilary losses are activated
"""
features, pos = self.backbone(samples)

src, mask = features[-1].decompose()

hs = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1])[0]
outputs_class = self.class_embed(hs)
outputs_coord = self.bbox_embed(hs).sigmoid()
out = {'pred_logits': outputs_class[-1], 'pred_boxes': outputs_coord[-1]}
if self.aux_loss:
    out['aux_outputs'] = self._set_aux_loss(outputs_class, outputs_coord)
return out
```

### 1ï¸âƒ£ Backbone
```python
position_embedding = build_position_encoding(args) # PE_sine or PE_learned
backbone = Backbone(args.backbone)
model = Joiner(backbone, position_embedding) # Joiner -> Backboneê³¼ PEë¥¼ ê²°í•©
model.num_channels = backbone.num_channels
return model 
```
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; initial image &nbsp;:&nbsp; $\boldsymbol{x_{img} \in \mathbb{R}^{3 \times H_{0} \times W_{0}}}$
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; After Backbone &nbsp;:&nbsp; $\boldsymbol{f \in \mathbb{R}^{C \times H \times W}}$, &nbsp; ì—¬ê¸°ì„œ ì¼ë°˜ì ìœ¼ë¡œ $\boldsymbol{C = 2048}$ ì´ê³  $\boldsymbol{H, W = {H_0 \over 32}, {W_0 \over 32}}$
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1X1 Convolutionìœ¼ë¡œ $\boldsymbol{f}$ë¥¼ ìƒˆë¡œìš´ feature map $z_0$ë¥¼ ìƒì„±í•œë‹¤ : $\boldsymbol{z_0 \in \mathbb{R}^{d \times H \times W}}$

<br>

### 2ï¸âƒ£ Transformer.forward (src, mask, query_embed, pos_embed)
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; bs, c, H, W = src.shape
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; src $\boldsymbol{\in}$ (bs, C, H, W) &nbsp; $\boldsymbol{\Rightarrow}$ &nbsp; src.flatten(2).permute(2, 0, 1) $\boldsymbol{\in}$ (H$\boldsymbol{\times}$W, bs, C)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mask $\boldsymbol{\in}$ (bs, H, W) &nbsp; $\boldsymbol{\Rightarrow}$ &nbsp; mask.flatten(1) $\boldsymbol{\in}$ (bs, H$\boldsymbol{\times}$w)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; query_embed $\boldsymbol{\in}$ (n_q, d) &nbsp; $\boldsymbol{\Rightarrow}$ &nbsp; query_embed.unsqueeze(1).repeat(1, bs, 1) $\boldsymbol{\in}$ (n_q, bs, d)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tgt = torch.zeros_like(query_embed) $\boldsymbol{\in}$ (n_q, bs, d)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; memory = TransformerEncoder(src, key_padding_mask = mask, pos = pos_embed) $\boldsymbol{\in}$ (H$\boldsymbol{\times}$W, bs, d)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; hs = TransformerDecoder(tgt, memory, memory_key_padding_mask = mask, pos = pos_embed, query_pos = query_embed) $\boldsymbol{\in}$ (n_layer, n_q, bs, d)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return hs.transpose(1, 2) $\boldsymbol{\in}$ (n_layer, bs, n_q, d), &nbsp; memory.permute(1, 2, 0).view(bs, c, H, W) $\boldsymbol{\in}$ (bs, d, H, W)

### 3ï¸âƒ£ TransformerEncoder.forward (src, src_key_padding_mask = mask, pos = pos_embed)
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output = src
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for layer in TransformerEncoderLayer:
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; output = layer(output, src_mask = mask, src_key_padding_mask = src_key_padding_mask, pos = pos)






### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br>
<br>


## ğŸ” Loss Function


<br>
<br>
