{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ccbcde",
   "metadata": {},
   "source": [
    "# 🚞 ABSTRACT - 초록\n",
    "\n",
    "- #### 이 논문은 large-scale image recognition setting에서 CNN의 깊이(depth)가 정확도에 미치는 영향을 연구한다.\n",
    "- #### 저자들은 3X3 Convolution Filter가 있는 구조를 사용하여 깊이가 증가하는 네트워크를 철저하게 평가하고<br/><br/>이 Filter를 깊이가 16 ~ 19인 가중치 layer에 넣어 이전의 구성보다 발전된 결과를 달성하였음을 보여준다.\n",
    "- #### 위 결과는 2014년의 ImageNet Challenge 2014 submission의 기초가 되었으며, 이들은 localisation과 classification tracks 에서 각각 1위와 2위를 차지하였다.\n",
    "- #### 저자들은 그들의 representation이 다른 dataset에도 잘 일반화되어 최고수준의 결과를 달성한다는 것을 설명한다.\n",
    "- #### 또, 저자들은 Computer Vision의 Deep visual representations에 대한 추가적인 연구를 용이하게 하기 위해 가장 성능이 좋은 두 개의 ConvNet 모델을 공개적으로 사용할 수 있도록 하였다.\n",
    "\n",
    "\n",
    "# 🚞 INTRODUCTION - 소개\n",
    "- #### 이 부분에서, 저자들은 기존의 ConvNet에 대해서 설명하고, 기존의 ConvNet을 개선한 architecture들을 소개한다.\n",
    "- #### 기존의 방법 -> [smaller receptive field와 smaller stride를 사용한 ILSVRC2013 (Zeiler & Fergus, 2013; Sermanet et al., 2014)  &&   image와 multiple scale에 걸쳐 빽빽하게 네트워크를 훈련하고 테스트 (Sermanet et al., 2014; Howard, 2014)]\n",
    "- #### 그리고 이 논문에서는 ConvNet Architecture 설계의 또 다른 중요한 측면인 깊이(Depth)를 다룰것이라 소개한다.\n",
    "- #### 이를 위해 Architecture의 다른 parameter를 수정하고 Convolution layer를 사용하여 네트워크의 깊이를 꾸준히 증가시키는데, 이것은 모든 layer에서 작은 크기의 (3X3) Convolution filter를 사용하기 때문에 가능하다.\n",
    "- #### 결과적으로 저자들은 ILSVRC classification 와 localisation 작업에 대해 최고 수준의 정확도를 달성할 뿐만 아니라 훨씬 더 정확한 ConvNet을 고안하였다. 이 ConvNet은 다른 이미지 dataset에 적용할 수 있으며 비교적 단순한 파이프라인의 일부로 사용하더라도 우수한 성능을 보인다고 한다.\n",
    "- #### 그리고 논문의 나머지 구성에 대해 얘기하는데, 2장은 ConvNet 구성에 대해 설명하고, 3장은 이미지 분류 및 평가에 대한 자세한 내용, 5장은 논문을 마무리하는 부분으로 구성되어 있다.\n",
    "- #### 추가적으로, 완전성을 위해 ILSVRC-2014 object localisation 시스템을 Appendix A 에서 설명하고, 다른 dataset에 대한 매우 심층적인 기능의 일반화에 대해서도 설명한다고 한다.\n",
    "\n",
    "\n",
    "# 🚞 CONVNET CONFIGURATIONS - ConvNet 구성\n",
    "- ### 공정한 환경에서의 실험을 위해, 저자들은 ConvNet 깊이의 증가로 인한 개선을 측정하기 위해 모든 ConvNet layer의 구성은 Ciresan et al.(2011); Krizhevsky et al. (2012) 에서 영감을 받아 동일한 원칙을 사용하여 설계하였다.\n",
    "- ### 이 section에서는 먼저 ConvNet 구성의 일반적인 layout을 설명한 다음, 평가에 사용된 특정 구성을 자세히 설명한다. 그런 다음 저자들의 design choice에 대해 논의하고 이전의 기술과 비교한다.\n",
    "\n",
    "\n",
    "+ #### 🛤 ARCHITECTURE - 구조\n",
    "    - #### Train을 하는 동안, ConvNet에 대한 입력은 고정된 크기인 (224X224) pixel의 RGB 이미지이다.  \n",
    "    - #### 전처리 과정으로는 각 픽셀에서 Train세트를 기반으로 계산된 평균 RGB 값을 빼는 것만 수행한다.  \n",
    "    - #### image는 Convolution layer의 stack을 통해 전달되며, 저자는 매우 작은 receptive field(3X3)을 가진 filter를 사용한다.  \n",
    "    - #### 한 가지 구성으로, (1X1) Conv filter를 사용하여 입력 채널의 linear transformation(비선형 함수 뒤에 이어지는)으로 볼 수 있다.  \n",
    "    - #### Convolution stride는 1로 고정되어 있으며 Convolution layer input의 spatial padding은 convolution 연산 후 spatial resolution이 보존되도록 조정된다. 즉, (3X3) Convolution layer에 대해 padding은 1 pixel이다.  \n",
    "    - #### spatial pooling은 일부 Conv layer 뒤에 따라오는 5개의 MaxPooling layer에 의해 수행된다.(모든 Conv layer가 MaxPooling을 따르는 것은 아님)\n",
    "    - #### MaxPooling은 (2X2) pixel window를 사용하여 2 pixel 간격으로 수행된다.\n",
    "    - #### Convolutional layer의 stack 다음에는 세 개의 Fully-Connected 레이어가 따릅니다. 첫번째, 두번째 FC layer는 각각 4096개의 채널을 가지며, 세번째 FC 레이어는 1000개의 채널을 가지며 1000개의 클래스에 대한 ILSVRC (ImageNet Large Scale Visual Recognition Challenge) 분류를 수행한다.\n",
    "    - #### 마지막 layer는 softmax layer입니다. Fully Connected layer의 구성은 모든 network에서 동일하다.\n",
    "    - #### 모든 hidden layer에는 ReLU (ReLU (Krizhevsky et al., 2012)) 비선형 함수가 적용된다.\n",
    "    - #### 저자의 네트워크 중 (하나를 제외하고) 어떤 네트워크도 Local Response Normalisation (LRN) 정규화 (Krizhevsky et al., 2012)를 포함하지 않는다. ILSVRC 데이터셋의 성능 향상에는 도움이 되지 않으며, 메모리 사용량과 계산 시간이 증가하는 경향이 있다고 한다. \n",
    "                \n",
    "\n",
    "+ #### 🛤 CONFIGURATIONS - 구성\n",
    "    - #### 이 논문에서 평가된 ConvNet 구성은 각각 테이블 1에 개별적으로 설명되어 있다. 이후에는 각 네트워크를 이름(A-E)으로 참조한다.  모든 구성은 2.1절에서 제시한 일반적인 디자인을 따르며, 깊이만 다르다. 네트워크 A에서는 11개의 가중치 레이어(8개의 Conv layer와 3개의 FC layer)가 있고, 네트워크 E에서는 19개의 가중치 레이어(16개의 Conv layer와 3개의 FC layer)가 있다.   Conv layer의 너비(채널 수)는 상당히 작으며, 첫번째 layer에서 64에서 시작하여 MaxPooling layer마다 2배씩 증가하고, 512까지 도달합니다.\n",
    "                \n",
    "\n",
    "+ #### 🛤 DISCUSSION - 논의\n",
    "    + #### 이 부분에서, 저자들은 ILSVRC-2012 (Krizhevsky et al., 2012) 및 ILSVRC-2013 대회 (Zeiler & Fergus, 2013; Sermanet et al., 2014)에서 사용된 ConvNet과 자신들의 ConvNet의 구성 차이를 설명한다.\n",
    "    - #### 저자들은 기존의 방법인 11×11 with stride 4 in (Krizhevsky et al., 2012), 또는 7×7 with stride 2 in (Zeiler & Fergus, 2013; Sermanet et al., 2014)처럼 큰 receptive field를 사용하는 대신에, 매우 작은 (3×3) receptive field를 사용하며, 이들은 모든 픽셀에서 input과 convolution연산을 수행한다(stride 1).\n",
    "    - #### spatial pooling이 없이, 두 개의 3×3 conv layers의 stack의 effective receptive field은 5×5이고, 이러한 3개의 layer는 7×7의 effective receptive field를 가지고 있음을 쉽게 알 수 있다.\n",
    "    - #### 그래서 single 7×7 layer 대신에 3개의 3×3 Conv layer stack을 사용함으로써 얻는 이점이 무엇일까?\n",
    "    - #### 첫째, single layer 대신에 3개의 non-linear rectification layers를 통합하여 dicision function를 더 차별적으로 만든다.\n",
    "    - #### 둘째, parameter 수를 줄인다. 예를들어, 입력과 출력이 C개의 channel을 가진 3개의 3×3 conv stack의 경우, stack은 3×(3^2 × C^2) = 27×C^2\n",
    "\n",
    "# 🚞 CLASSIFICATION FRAMEWORK\n",
    "\n",
    "# 🚞  CLASSIFICATION EXPERIMENTS\n",
    "\n",
    "# 🚞 CONCLUSION\n",
    "\n",
    "# 🚌LOCALISATION\n",
    "\n",
    "# 🚌 GENERALISATION OF VERY DEEP FEATURES\n",
    "\n",
    "# 🚌 PAPER REVISIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45e952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
